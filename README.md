# 🧠 Task 4: Prediction Model using Logistic Regression

This repository contains **Task 4** from my internship at **CodeTech**, where I built a supervised classification model using **Logistic Regression**. The objective was to analyze a dataset, remove duplicates, build models, evaluate them, and use the best one for prediction.

---

## 📌 Project Objective

- To preprocess and clean the dataset
- To build two models:
  - One using the full dataset
  - One after removing 70%+ duplicate entries
- To compare the models using evaluation metrics
- To select the best model for future predictions

---

## 🛠️ Tools & Technologies Used

- `Python 3.x`
- `pandas`
- `scikit-learn`
- `seaborn`, `matplotlib` (for data visualization)
- `Jupyter Notebook`

---

## 📂 File Structure

```bash
📦 Task_4_Prediction_Model
 ┣ 📄 Task_4_Prediction_model.ipynb
 ┗ 📄 README.md
````

---

## 📊 Project Highlights

* ✅ **Data Cleaning**: Identified and removed \~70% duplicates
* ✅ **Modeling**: Created 2 models using Logistic Regression
* ✅ **Evaluation**: Used Confusion Matrix and Classification Report
* ✅ **Final Decision**: Model without duplicates showed better performance and was used for predictions

---

## 📈 Performance Metrics

* **Confusion Matrix** for both models
* **Precision, Recall, F1-Score**
* **Model Comparison** and justification for choosing the better model

---

## 📌 How to Run

1. Clone this repository:

   ```bash
   git clone https://github.com/your-username/Task_4_Prediction_Model.git
   cd Task_4_Prediction_Model
   ```

2. Install the required libraries:

   ```bash
   pip install pandas scikit-learn matplotlib seaborn
   ```

3. Open the notebook:

   ```bash
   jupyter notebook Task_4_Prediction_model.ipynb
   ```

---

## 🏁 Learning Outcomes

* Gained experience in real-world data cleaning
* Understood model comparison techniques
* Learned to visualize performance and make informed model choices
* Strengthened skills in building predictive systems
